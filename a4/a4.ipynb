{"cells":[{"cell_type":"code","execution_count":47,"id":"49f0f4fb","metadata":{},"outputs":[],"source":["from pyspark.sql import SparkSession"]},{"cell_type":"code","execution_count":48,"id":"e9d85c3a","metadata":{},"outputs":[],"source":["spark = SparkSession.builder.appName(\"a4\").getOrCreate()"]},{"cell_type":"code","execution_count":49,"id":"6310a779","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["+---------------+------------+------------+------------+\n","|passenger_count|pulocationid|dolocationid|total_amount|\n","+---------------+------------+------------+------------+\n","|            1.0|       151.0|       239.0|        9.95|\n","|            1.0|       239.0|       246.0|        16.3|\n","|            3.0|       236.0|       236.0|         5.8|\n","|            5.0|       193.0|       193.0|        7.55|\n","|            5.0|       193.0|       193.0|       55.55|\n","|            5.0|       193.0|       193.0|       13.31|\n","|            5.0|       193.0|       193.0|       55.55|\n","|            1.0|       163.0|       229.0|        9.05|\n","|            1.0|       229.0|         7.0|        18.5|\n","|            2.0|       141.0|       234.0|        13.0|\n","+---------------+------------+------------+------------+\n","only showing top 10 rows\n","\n"]}],"source":["# 1. Creating the dataset\n","file_path = \"gs://dataproc-staging-us-central1-1022936215757-ezcuz3ds/data/reduced_2019.csv\"\n","df = spark.read.csv(file_path, header=True, inferSchema=True)\n","df.show(10)"]},{"cell_type":"code","execution_count":50,"id":"05984ee1","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[Stage 134:============================>                            (1 + 1) / 2]\r"]},{"name":"stdout","output_type":"stream","text":["There are 2920384 rows in the training set, and 730615 in the test set\n"]},{"name":"stderr","output_type":"stream","text":["\r","                                                                                \r"]}],"source":["# 2. Create trainDF and testDF\n","trainDF, testDF = df.randomSplit([0.8,0.2], seed=42)\n","print(f\"\"\"There are {trainDF.count()} rows in the training set, and {testDF.count()} in the test set\"\"\")"]},{"cell_type":"code","execution_count":51,"id":"351c0098","metadata":{},"outputs":[],"source":["from pyspark.ml.feature import VectorAssembler"]},{"cell_type":"code","execution_count":52,"id":"7eba18d5","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["\r","[Stage 137:>                                                        (0 + 1) / 1]\r"]},{"name":"stdout","output_type":"stream","text":["+---------------+------------+------------+------------+-------------+\n","|passenger_count|pulocationid|dolocationid|total_amount|     features|\n","+---------------+------------+------------+------------+-------------+\n","|            0.0|         1.0|         1.0|        90.0|[0.0,1.0,1.0]|\n","|            0.0|         1.0|         1.0|      101.39|[0.0,1.0,1.0]|\n","|            0.0|         1.0|         1.0|      116.75|[0.0,1.0,1.0]|\n","|            0.0|         1.0|         1.0|      132.35|[0.0,1.0,1.0]|\n","|            0.0|         1.0|         1.0|       172.8|[0.0,1.0,1.0]|\n","+---------------+------------+------------+------------+-------------+\n","only showing top 5 rows\n","\n"]},{"name":"stderr","output_type":"stream","text":["\r","                                                                                \r"]}],"source":["vecAss = VectorAssembler(inputCols=[\"passenger_count\", \"pulocationid\", \"dolocationid\"], outputCol=\"features\")\n","vecTrainDF = vecAss.transform(trainDF)\n","vecTrainDF.show(5)"]},{"cell_type":"code","execution_count":53,"id":"eea2355c","metadata":{},"outputs":[],"source":["from pyspark.ml.regression import DecisionTreeRegressor"]},{"cell_type":"code","execution_count":54,"id":"ff27631f","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["dtr = DecisionTreeRegressor(featuresCol='features', labelCol = 'total_amount')\n","dtr.setMaxBins(64)\n","lrModel = dtr.fit(vecTrainDF)"]},{"cell_type":"code","execution_count":55,"id":"17e7ce60","metadata":{},"outputs":[],"source":["from pyspark.ml import Pipeline"]},{"cell_type":"code","execution_count":56,"id":"887f19f8","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["pipeline = Pipeline(stages = [vecAss, dtr])\n","pipelineModel = pipeline.fit(trainDF)"]},{"cell_type":"code","execution_count":59,"id":"c43f675e","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["\r","[Stage 168:>                                                        (0 + 1) / 1]\r"]},{"name":"stdout","output_type":"stream","text":["+---------------+------------+------------+------------------+\n","|passenger_count|pulocationid|dolocationid|        prediction|\n","+---------------+------------+------------+------------------+\n","|            0.0|         1.0|         1.0| 18.40309286568426|\n","|            0.0|         4.0|         4.0| 18.40309286568426|\n","|            0.0|         4.0|         4.0| 18.40309286568426|\n","|            0.0|         4.0|        68.0|13.650920445112941|\n","|            0.0|         4.0|        79.0|13.650920445112941|\n","|            0.0|         4.0|        80.0|13.650920445112941|\n","|            0.0|         4.0|       107.0|13.650920445112941|\n","|            0.0|         4.0|       114.0|13.650920445112941|\n","|            0.0|         4.0|       161.0|13.650920445112941|\n","|            0.0|         4.0|       161.0|13.650920445112941|\n","+---------------+------------+------------+------------------+\n","only showing top 10 rows\n","\n"]},{"name":"stderr","output_type":"stream","text":["\r","                                                                                \r"]}],"source":["predDF = pipelineModel.transform(testDF)\n","predDF.select('passenger_count','pulocationid', 'dolocationid','prediction' ).show(10)"]},{"cell_type":"code","execution_count":60,"id":"9b4591d9","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[Stage 169:============================>                            (1 + 1) / 2]\r"]},{"name":"stdout","output_type":"stream","text":["50.98573622802005\n"]},{"name":"stderr","output_type":"stream","text":["\r","                                                                                \r"]}],"source":["from pyspark.ml.evaluation import RegressionEvaluator\n","\n","regressionEvaluator = RegressionEvaluator(\n","    predictionCol=\"prediction\",\n","    labelCol=\"total_amount\",\n","    metricName=\"rmse\")\n","\n","rmse = regressionEvaluator.evaluate(predDF)\n","print(rmse)"]},{"cell_type":"code","execution_count":null,"id":"057a5903","metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"PySpark","language":"python","name":"pyspark"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"}},"nbformat":4,"nbformat_minor":5}